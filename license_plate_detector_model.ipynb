{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "980c2aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def visualize_annotations(image_path, label_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    h, w = img.shape[:2]\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            class_id, x, y, width, height = map(float, parts)\n",
    "            x1 = int((x - width/2) * w)\n",
    "            y1 = int((y - height/2) * h)\n",
    "            x2 = int((x + width/2) * w)\n",
    "            y2 = int((y + height/2) * h)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.imshow('Annotated Image', img)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91222ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.228 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.203  Python-3.10.0 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\abdal\\Downloads\\Compressed\\archive\\EALPR Vechicles dataset\\YOLO_Format_Data\\lp_detection.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov9s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\abdal\\AppData\\Local\\Programs\\Microsoft VS Code\\runs\\detect\\train5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     31104  ultralytics.nn.modules.block.ELAN1           [64, 64, 64, 32]              \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.block.AConv           [64, 128]                     \n",
      "  4                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  5                  -1  1    221568  ultralytics.nn.modules.block.AConv           [128, 192]                    \n",
      "  6                  -1  1    579648  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 192, 192, 96, 3]        \n",
      "  7                  -1  1    442880  ultralytics.nn.modules.block.AConv           [192, 256]                    \n",
      "  8                  -1  1   1028864  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 256, 256, 128, 3]       \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPELAN         [256, 256, 128]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    628800  ultralytics.nn.modules.block.RepNCSPELAN4    [448, 192, 192, 96, 3]        \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    283008  ultralytics.nn.modules.block.RepNCSPELAN4    [320, 128, 128, 64, 3]        \n",
      " 16                  -1  1    110784  ultralytics.nn.modules.block.AConv           [128, 96]                     \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    598080  ultralytics.nn.modules.block.RepNCSPELAN4    [288, 192, 192, 96, 3]        \n",
      " 19                  -1  1    221440  ultralytics.nn.modules.block.AConv           [192, 128]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1061632  ultralytics.nn.modules.block.RepNCSPELAN4    [384, 256, 256, 128, 3]       \n",
      " 22        [15, 18, 21]  1   1563475  ultralytics.nn.modules.head.Detect           [1, [128, 192, 256]]          \n",
      "YOLOv9s summary: 544 layers, 7,287,795 parameters, 7,287,779 gradients, 27.4 GFLOPs\n",
      "\n",
      "Transferred 1333/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 163.783.9 MB/s, size: 67.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\abdal\\Downloads\\Compressed\\archive\\EALPR Vechicles dataset\\YOLO_Format_Data\\train\\labels.cache... 1668 images, 0 backgrounds, 1 corrupt: 100% ━━━━━━━━━━━━ 1669/1669 1.7Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\abdal\\Downloads\\Compressed\\archive\\EALPR Vechicles dataset\\YOLO_Format_Data\\train\\images\\2018.jpg: ignoring corrupt image/label: image file is truncated (5 bytes not processed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abdal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.2 ms, read: 81.521.9 MB/s, size: 59.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\abdal\\Downloads\\Compressed\\archive\\EALPR Vechicles dataset\\YOLO_Format_Data\\val\\labels.cache... 209 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 209/209 103.9Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\abdal\\Downloads\\Compressed\\archive\\EALPR Vechicles dataset\\YOLO_Format_Data\\val\\images\\0631.JPG: corrupt JPEG restored and saved\n",
      "Plotting labels to C:\\Users\\abdal\\AppData\\Local\\Programs\\Microsoft VS Code\\runs\\detect\\train5\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.0005), 227 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(7e63ba3b42a442a49f54afcbf038ee6c) to runs\\mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mview at http://127.0.0.1:5000 with 'mlflow server --backend-store-uri runs\\mlflow'\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\abdal\\AppData\\Local\\Programs\\Microsoft VS Code\\runs\\detect\\train5\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.62G      0.709     0.9873      0.941          8        640: 100% ━━━━━━━━━━━━ 209/209 2.6it/s 1:20<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 4.3it/s 3.3s0.2s\n",
      "                   all        209        213      0.975      0.986      0.994      0.814\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.48G     0.7333     0.5665     0.9703          4        640: 100% ━━━━━━━━━━━━ 209/209 3.3it/s 1:04<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 5.1it/s 2.8s0.2s\n",
      "                   all        209        213      0.958       0.96      0.986      0.836\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.48G     0.7027     0.5254     0.9857          9        640: 100% ━━━━━━━━━━━━ 209/209 3.4it/s 1:02<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 5.1it/s 2.8s0.2s\n",
      "                   all        209        213      0.976      0.962      0.983      0.835\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.45G      0.666     0.4619     0.9606          7        640: 100% ━━━━━━━━━━━━ 209/209 3.1it/s 1:08<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 4.4it/s 3.2s0.2s\n",
      "                   all        209        213          1      0.975      0.995       0.86\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.48G     0.6593     0.4487     0.9616         12        640: 100% ━━━━━━━━━━━━ 209/209 3.1it/s 1:07<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 4.6it/s 3.0s0.2s\n",
      "                   all        209        213      0.986      0.982      0.994      0.837\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.48G     0.6379       0.42     0.9567          9        640: 100% ━━━━━━━━━━━━ 209/209 3.3it/s 1:03<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 5.1it/s 2.7s0.2s\n",
      "                   all        209        213      0.991      0.985      0.994       0.86\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.48G     0.6012     0.4004     0.9398          7        640: 100% ━━━━━━━━━━━━ 209/209 3.3it/s 1:03<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 4.7it/s 3.0s0.2s\n",
      "                   all        209        213          1      0.991      0.995      0.872\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.48G     0.5794     0.3781     0.9357          8        640: 100% ━━━━━━━━━━━━ 209/209 3.3it/s 1:04<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 5.0it/s 2.8s0.2s\n",
      "                   all        209        213      0.994      0.991      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.48G     0.5708     0.3651     0.9298          8        640: 100% ━━━━━━━━━━━━ 209/209 3.3it/s 1:02<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 4.8it/s 2.9s0.2s\n",
      "                   all        209        213      0.986      0.999      0.995      0.883\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.48G     0.5673     0.3499     0.9275          9        640: 100% ━━━━━━━━━━━━ 209/209 3.4it/s 1:02<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 5.1it/s 2.8s0.2s\n",
      "                   all        209        213      0.997      0.991      0.995      0.879\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.48G     0.5308     0.3199     0.9149          4        640: 100% ━━━━━━━━━━━━ 209/209 3.4it/s 1:02<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 4.8it/s 2.9s0.2s\n",
      "                   all        209        213      0.994      0.991      0.995      0.889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.45G     0.5255     0.3104     0.9188          4        640: 100% ━━━━━━━━━━━━ 209/209 3.3it/s 1:04<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 5.1it/s 2.8s0.2s\n",
      "                   all        209        213      0.995      0.991      0.995      0.896\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.48G     0.5164     0.3044     0.9141          6        640: 100% ━━━━━━━━━━━━ 209/209 3.3it/s 1:03<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 4.7it/s 3.0s0.2s\n",
      "                   all        209        213      0.995      0.972      0.993      0.894\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.48G     0.4999     0.2952     0.9077          4        640: 100% ━━━━━━━━━━━━ 209/209 3.4it/s 1:02<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 4.9it/s 2.8s0.2s\n",
      "                   all        209        213      0.995      0.995      0.995      0.895\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.48G     0.4818     0.2769     0.8957          4        640: 100% ━━━━━━━━━━━━ 209/209 3.3it/s 1:03<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 4.9it/s 2.9s0.2s\n",
      "                   all        209        213      0.995      0.994      0.995      0.893\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.48G     0.4769     0.2617      0.892          4        640: 100% ━━━━━━━━━━━━ 209/209 3.4it/s 1:02<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 4.9it/s 2.8s0.2s\n",
      "                   all        209        213      0.999      0.991      0.995      0.906\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.48G     0.4609     0.2548     0.8944          4        640: 100% ━━━━━━━━━━━━ 209/209 3.3it/s 1:03<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 5.0it/s 2.8s0.2s\n",
      "                   all        209        213          1       0.99      0.995        0.9\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.48G     0.4533     0.2454     0.8894          4        640: 100% ━━━━━━━━━━━━ 209/209 3.3it/s 1:03<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 4.9it/s 2.9s0.2s\n",
      "                   all        209        213          1      0.995      0.995       0.91\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.48G     0.4406     0.2335     0.8765          4        640: 100% ━━━━━━━━━━━━ 209/209 3.1it/s 1:07<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 4.8it/s 2.9s0.2s\n",
      "                   all        209        213          1      0.995      0.995      0.909\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.45G     0.4305     0.2234     0.8714          4        640: 100% ━━━━━━━━━━━━ 209/209 3.3it/s 1:03<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 4.8it/s 2.9s0.2s\n",
      "                   all        209        213          1      0.991      0.995      0.916\n",
      "\n",
      "20 epochs completed in 0.389 hours.\n",
      "Optimizer stripped from C:\\Users\\abdal\\AppData\\Local\\Programs\\Microsoft VS Code\\runs\\detect\\train5\\weights\\last.pt, 15.2MB\n",
      "Optimizer stripped from C:\\Users\\abdal\\AppData\\Local\\Programs\\Microsoft VS Code\\runs\\detect\\train5\\weights\\best.pt, 15.2MB\n",
      "\n",
      "Validating C:\\Users\\abdal\\AppData\\Local\\Programs\\Microsoft VS Code\\runs\\detect\\train5\\weights\\best.pt...\n",
      "Ultralytics 8.3.203  Python-3.10.0 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 4.3it/s 3.2s0.2s\n",
      "                   all        209        213          1      0.991      0.995      0.917\n",
      "Speed: 0.3ms preprocess, 8.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\abdal\\AppData\\Local\\Programs\\Microsoft VS Code\\runs\\detect\\train5\u001b[0m\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mresults logged to runs\\mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch  # أضف هذا السطر\n",
    "\n",
    "# تحميل نموذج أساسي (pre-trained على COCO)\n",
    "model = YOLO('yolov9s.pt')  # n للنسخة الصغيرة، استخدم yolov8s لأفضل دقة\n",
    "\n",
    "# تدريب\n",
    "model.train(data=r\"C:\\Users\\abdal\\Downloads\\Compressed\\archive\\EALPR Vechicles dataset\\YOLO_Format_Data\\lp_detection.yaml\", epochs=20, imgsz=640, batch=8, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# حفظ النموذج\n",
    "model.save(r'C:\\Users\\abdal\\Desktop\\project\\models\\license_plate_detector.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ba0ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.203  Python-3.10.0 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "YOLOv9s summary (fused): 197 layers, 7,167,475 parameters, 0 gradients, 26.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 709.5335.2 MB/s, size: 110.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\abdal\\Downloads\\Compressed\\archive\\EALPR Vechicles dataset\\YOLO_Format_Data\\val\\labels.cache... 209 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 209/209 104.5Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\abdal\\Downloads\\Compressed\\archive\\EALPR Vechicles dataset\\YOLO_Format_Data\\val\\images\\0631.JPG: corrupt JPEG restored and saved\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 14/14 2.7it/s 5.3s0.3s\n",
      "                   all        209        213          1      0.991      0.995      0.917\n",
      "Speed: 0.9ms preprocess, 13.0ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\abdal\\AppData\\Local\\Programs\\Microsoft VS Code\\runs\\detect\\val3\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\abdal\\Downloads\\Compressed\\archive\\EALPR Vechicles dataset\\YOLO_Format_Data\\test\\images\\0234.jpg: 640x640 1 license_plate, 33.2ms\n",
      "Speed: 4.5ms preprocess, 33.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# تحميل النموذج المدرب\n",
    "model = YOLO(r'C:\\Users\\abdal\\Desktop\\project\\models\\license_plate_detector.pt')\n",
    "\n",
    "# تقييم\n",
    "results = model.val(data=r\"C:\\Users\\abdal\\Downloads\\Compressed\\archive\\EALPR Vechicles dataset\\YOLO_Format_Data\\lp_detection.yaml\")\n",
    "\n",
    "# اختبار على صورة جديدة\n",
    "results = model(r\"C:\\Users\\abdal\\Downloads\\Compressed\\archive\\EALPR Vechicles dataset\\YOLO_Format_Data\\test\\images\\0234.jpg\")\n",
    "results[0].show()  # عرض النتائج"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
